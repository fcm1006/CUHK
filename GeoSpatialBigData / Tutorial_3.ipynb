{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fcm1006/CUHK/blob/GISM/GeoSpatialBigData%20/%20Tutorial_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Oyo84mxi49"
      },
      "source": [
        "# 1 Clustering on spatial data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cluster algorithms are useful for spatial data because they allow us to **group together similar data points based on their proximity to one another.** This can help us identify patterns and relationships in the data that might not be immediately apparent when looking at individual data points.\n",
        "\n",
        "For example, if we have a dataset of customer locations, we might use a cluster algorithm to group together customers who are located near one another. This could help us identify areas where we might want to open a new store or target our marketing efforts.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDkAfBcG2Nia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://asmaloney.com/images/2015/06/Leaflet_Clusters_Too_Many_Markers.jpg\"/>"
      ],
      "metadata": {
        "id": "oMxHWuJFAkTX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M25fKQAgy2bj"
      },
      "source": [
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/merge3cluster.jpg\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWuxH2K2x60v"
      },
      "source": [
        "## 1.1 Clustering algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rrZyCUQy78L"
      },
      "source": [
        "Different clustering algorithm\n",
        "\n",
        "https://scikit-learn.org/stable/modules/clustering.html\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/700/1*oNt9G9UpVhtyFLDBwEMf8Q.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBbTftx8zUna"
      },
      "source": [
        "How DBScan works\n",
        "\n",
        "https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgj0srpSzhha"
      },
      "source": [
        "<img src=\"https://miro.medium.com/proxy/1*tc8UF-h0nQqUfLC8-0uInQ.gif\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr3I4cddWiCl"
      },
      "source": [
        "## 1.2 Try DBsscan on test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK5TFdu0zkHd"
      },
      "source": [
        "Let's try it\n",
        "\n",
        "<img src=\"https://i.redd.it/142fd50lrqu21.jpg\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLISUyyAztCs"
      },
      "source": [
        "!pip install sklearn # an important machine learning package"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRQGN5wJWwKK"
      },
      "source": [
        "# Generate some random coordinates at Shanghai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "sh_lat = 31.22 \n",
        "sh_lng = 121.46\n",
        "\n",
        "data, label = make_blobs(n_samples=100, n_features=2, centers=5) # five clusters, randomly\n",
        "\n",
        "sample_data =pd.DataFrame(data = data*0.01 + np.array([sh_lat,sh_lng]),  \n",
        "                  columns = [\"y\", \"x\"]) \n",
        "\n",
        "sample_data.head(10) # show the top rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnR84AZr0vRg"
      },
      "source": [
        "# plot in map\n",
        "!pip install folium\n",
        "import folium\n",
        "\n",
        "gaode = 'http://wprd03.is.autonavi.com/appmaptile?style=7&x={x}&y={y}&z={z}' \n",
        "map_sh_random_pt = folium.Map(location=[sh_lat,sh_lng],tiles=gaode, attr = 'test')\n",
        "\n",
        "for index, row in sample_data.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        [row['y'],row['x']],\n",
        "        radius=3).add_to(map_sh_random_pt)\n",
        "map_sh_random_pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGztYcjm08NT"
      },
      "source": [
        "# create a dbscan cluster\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "db_default = DBSCAN(eps = 0.01, # ~ 1000 meter\n",
        "                    min_samples = 3).fit(sample_data[['x','y']]) # train the model \n",
        "\n",
        "sample_data['label'] = db_default.fit_predict(sample_data[['x','y']]) # assign the clustering result\n",
        "\n",
        "sample_data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://wondernote.org/wp-content/uploads/2019/03/Bright-Color-Palettes-Wondernote.jpg\" height=\"500\">"
      ],
      "metadata": {
        "id": "qe3hIQBKGxK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_sh_random_pt_cluster = folium.Map(location=[sh_lat,sh_lng],tiles=gaode, attr = 'test')\n",
        "\n",
        "# find a color palettes\n",
        "colors = ['#c05780', '#ff828b', '#e7c582', '#00b0ba', '#0065a2', '#ffec59' '#555555']\n",
        "\n",
        "for index, row in sample_data.iterrows():\n",
        "  folium.CircleMarker(\n",
        "      [row['y'],row['x']],\n",
        "      color = colors[int(row['label'])],\n",
        "      radius=3,\n",
        "      fill=True\n",
        "  ).add_to(map_sh_random_pt_cluster)\n",
        "\n",
        "map_sh_random_pt_cluster"
      ],
      "metadata": {
        "id": "Bl3c4eB9DjOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di8URkgXys0T"
      },
      "source": [
        "## 1.3 Shared bike O-D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skl0BLdGyJBL"
      },
      "source": [
        "# load a mobike data in Shanghai\n",
        "mobike_df = pd.read_csv('https://github.com/gyshion/tutorial/raw/main/mobike_shanghai1.csv')\n",
        "mobike_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE9Zjy7fyZPy"
      },
      "source": [
        "# Plot 1% of the Origin-destination line from mobike data\n",
        "\n",
        "map_sh = folium.Map(location=[sh_lat,sh_lng],tiles=gaode, attr = 'shared bike')\n",
        "\n",
        "for index, row in mobike_df.iterrows():\n",
        "    if index%100 == 0:\n",
        "    #if index%10 == 0:\n",
        "        OD = [\n",
        "            [row['start_location_y'],row['start_location_x']],\n",
        "            [row['end_location_y'],row['end_location_x']]]\n",
        "        \n",
        "        folium.PolyLine(OD, color='red').add_to(map_sh)\n",
        "map_sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQPRNY_u1DuJ"
      },
      "source": [
        "## 1.4 Try DBscan on Mobike dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNOmbhPT0_xI"
      },
      "source": [
        "# stack the origin points with destination points\n",
        "new_ll = []\n",
        "\n",
        "for index, row in mobike_df.iterrows():\n",
        "    new_ll.append([row['start_location_y'],row['start_location_x']])\n",
        "    new_ll.append([row['end_location_y'],row['end_location_x']])\n",
        "\n",
        "all_pt =pd.DataFrame(data = new_ll, columns = [\"y\", \"x\"]) \n",
        "\n",
        "all_pt.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnjj9Ujf1Nou"
      },
      "source": [
        "db_mobike = DBSCAN(eps = 0.0005, # ~ 50 meter\n",
        "                   min_samples = 20).fit(all_pt[['y','x']]) # train the model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvR5gtCh1P8h"
      },
      "source": [
        "predict_mobike = db_mobike.fit_predict(all_pt[['y','x']]) # predict by the model\n",
        "all_pt['label'] = predict_mobike\n",
        "\n",
        "all_pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O50RILkT1_oN"
      },
      "source": [
        "# assign color for different labels\n",
        "import random\n",
        "def random_color(seed):\n",
        "    random.seed(seed+10)\n",
        "    return \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
        "\n",
        "print(random_color(4435)) # return the same color code for same seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASuQOSrF1kGI"
      },
      "source": [
        "# check how many clusters we have\n",
        "np.unique(predict_mobike)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyY27tKZ1Sxh"
      },
      "source": [
        "map_sh_4 = folium.Map(location=[sh_lat,sh_lng],tiles=gaode,attr='test')\n",
        "\n",
        "for index, row in all_pt.iterrows():\n",
        "    if row['label']>=0:\n",
        "      if random.random()<0.02:\n",
        "        folium.CircleMarker(\n",
        "            [row['y'],row['x']],\n",
        "            color = random_color(row['label']),\n",
        "            radius=3,\n",
        "            fill=True\n",
        "        ).add_to(map_sh_4)\n",
        "map_sh_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uul2u8Gd10kc"
      },
      "source": [
        "# assign the cluster to OD points\n",
        "mobike_df['start_cluster'] = db_mobike.fit_predict(mobike_df[['start_location_y','start_location_x']]) # predict by the model\n",
        "mobike_df['end_cluster'] = db_mobike.fit_predict(mobike_df[['end_location_y','end_location_x']]) # predict by the model\n",
        "mobike_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter only the od among clusters\n",
        "\n",
        "mobike_df_cluster = mobike_df.query(\"start_cluster>=0 and end_cluster>=0\")\n",
        "mobike_df_cluster\n"
      ],
      "metadata": {
        "id": "GIMFuvW8c8CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVQ4N7dU14z9"
      },
      "source": [
        "# Plot 100% of the Origin-destination line from mobike data with the cluster\n",
        "\n",
        "map_sh_4 = folium.Map(location=[sh_lat,sh_lng],tiles=gaode,attr='test')\n",
        "\n",
        "for index, row in mobike_df_cluster.iterrows():\n",
        "    if index%1==0:\n",
        "        OD = [\n",
        "            [row['start_location_y'],row['start_location_x']],\n",
        "            [row['end_location_y'],row['end_location_x']]]\n",
        "        folium.PolyLine(OD,weight=0.5,color = 'black').add_to(map_sh_4)\n",
        "        \n",
        "        \n",
        "        folium.CircleMarker(\n",
        "            [row['start_location_y'],row['start_location_x']],\n",
        "            color = random_color(row['start_cluster']),\n",
        "            radius=3,\n",
        "            fill=True\n",
        "        ).add_to(map_sh_4)\n",
        "\n",
        "        folium.CircleMarker(\n",
        "            [row['end_location_y'],row['end_location_x']],\n",
        "            color = random_color(row['end_cluster']),\n",
        "            radius=3,\n",
        "            fill=True\n",
        "        ).add_to(map_sh_4)\n",
        "        \n",
        "map_sh_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# todo: extract the network from shared bike data"
      ],
      "metadata": {
        "id": "WxKosBUQeY4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ4vaNTE2bFr"
      },
      "source": [
        "# 2 Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGJ3IXfLZIb9"
      },
      "source": [
        "## 2.1 Network representing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfvn-3p22eLr"
      },
      "source": [
        "!pip install networkx --user # most important network module\n",
        "!pip install matplotlib --user\n",
        "import networkx as nx\n",
        "import matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WuMRcDC2t6_"
      },
      "source": [
        "G=nx.Graph() # create a network and add some edge\n",
        "\n",
        "# adding just one node:\n",
        "G.add_node(\"a\")\n",
        "# a list of nodes:\n",
        "G.add_nodes_from([\"b\",\"c\"])\n",
        "\n",
        "print(\"Nodes of graph: \")\n",
        "print(G.nodes())\n",
        "print(\"Edges of graph: \")\n",
        "print(G.edges())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmUjH_IK2x2-"
      },
      "source": [
        "# adding more of edges:\n",
        "G.add_edges_from([(\"a\",\"c\"),(\"c\",\"d\"), (\"a\",1), (1,\"d\"), (\"a\",2)])\n",
        "\n",
        "print(\"Nodes of graph: \")\n",
        "print(G.nodes())\n",
        "print(\"Edges of graph: \")\n",
        "print(G.edges())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewIMmWJr21oF"
      },
      "source": [
        "nx.draw(G,with_labels=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyIqCYZU28Jk"
      },
      "source": [
        "# Can you make this network connected as a whole?\n",
        "\n",
        "nx.draw(G,with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcEkMsux3CvO"
      },
      "source": [
        "## 2.2 Calculate node centrality index\n",
        "https://networkx.org/documentation/stable/reference/algorithms/centrality.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KII-9LUk2_DS"
      },
      "source": [
        "G2 = nx.random_geometric_graph(8, 0.4) # generate a network randomly: 50 nodes, located within x:[0 to 1], y:[0 to 1] by default\n",
        "# Two nodes are joined by an edge if the distance between the nodes <=0.4\n",
        "nx.draw(G2,with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jp2yCblMXND"
      },
      "source": [
        "closeness_centrality_map = nx.algorithms.centrality.closeness_centrality(G2)\n",
        "\n",
        "for k in closeness_centrality_map:\n",
        "  print(k, closeness_centrality_map[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPbg8VEiDLrl"
      },
      "source": [
        "betweenness_centrality_map = nx.algorithms.centrality.betweenness_centrality(G2)\n",
        "# print(betweenness_centrality_map)\n",
        "\n",
        "for k in betweenness_centrality_map:\n",
        "  print(k, betweenness_centrality_map[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is6w2bzQ3H_7"
      },
      "source": [
        "pos=nx.get_node_attributes(G2,'pos')\n",
        "pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y4bu6DW3LGP"
      },
      "source": [
        "nx.draw(G2,with_labels=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSXEFF4eZSCi"
      },
      "source": [
        "betweenness_centrality_map = nx.algorithms.centrality.betweenness_centrality(G2)\n",
        "# print(betweenness_centrality_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruT6jaFIZVMi"
      },
      "source": [
        "# plot the node with centrality level\n",
        "nx.draw_networkx_edges(G2, pos, alpha=0.4)\n",
        "nx.draw_networkx_nodes(\n",
        "    G2,\n",
        "    pos,\n",
        "    nodelist=list(betweenness_centrality_map.keys()),\n",
        "    node_size=80,\n",
        "    node_color=list(betweenness_centrality_map.values())\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfXCxT8LZgtm"
      },
      "source": [
        "## 2.3 Try on real data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2Rt1smdZj1E"
      },
      "source": [
        "# read the flight data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "flight_df = pd.read_csv('https://github.com/gyshion/tutorial/raw/main/flights.csv',sep=';')\n",
        "flight_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivrTTRghZgCz"
      },
      "source": [
        "# import the data into a new network\n",
        "\n",
        "G_flight=nx.Graph() \n",
        "\n",
        "pos_flight = dict() #store the location of airports\n",
        "\n",
        "for index, row in flight_df.iterrows():\n",
        "    if row['NbFlights']>4:\n",
        "        dep = str(row['DepLat'])+','+str(row['DepLon'])\n",
        "        arr = str(row['ArrLat'])+','+str(row['ArrLon'])\n",
        "        G_flight.add_edge(dep,arr,weight=row['NbFlights'])\n",
        "        pos_flight[dep] = [row['DepLon'],row['DepLat']]\n",
        "        pos_flight[arr] = [row['ArrLon'],row['ArrLat']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab2aw7pMZwWV"
      },
      "source": [
        "nx.draw(G_flight,pos=pos_flight,node_size=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttEQG-KiZzxG"
      },
      "source": [
        "# calculate the eigenvector_centrality\n",
        "\n",
        "eigenvector_centrality_map = nx.algorithms.centrality.eigenvector_centrality(G_flight,weight='weight')\n",
        "print(eigenvector_centrality_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWVVCK2xZ3E6"
      },
      "source": [
        "nx.draw(G_flight,pos=pos_flight,node_size=30,node_color=list(eigenvector_centrality_map.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNZe_NDgarY0"
      },
      "source": [
        "## 2.4 Plot it on folium\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp9GyvHbUX75"
      },
      "source": [
        "If we want to plot the airports with high importance, like larger than 0.1\n",
        "\n",
        "Can you try by yourselve?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opt43HUbavkC"
      },
      "source": [
        "map_sh_5 = folium.Map(location=[sh_lat,sh_lng],tiles=gaode,attr='test')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtaYE-tqjSxU"
      },
      "source": [
        "# all link of a graph\n",
        "for link in G_flight:\n",
        "  #print(link)\n",
        "  link"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZUg342flMih"
      },
      "source": [
        "# all node importance\n",
        "for k in eigenvector_centrality_map:\n",
        "  if eigenvector_centrality_map[k]>=0.1:\n",
        "      print('coor:',k,', eigenvector:',eigenvector_centrality_map[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# todo: plot the data on the folium map"
      ],
      "metadata": {
        "id": "aLjhOXCde_OR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}